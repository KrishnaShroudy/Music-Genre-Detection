{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f4f285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import misc\n",
    "import glob\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "from keras import layers\n",
    "from keras.layers import (Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, \n",
    "                          Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D)\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "import pydot\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.initializers import glorot_uniform\n",
    "from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n",
    "from pydub import AudioSegment\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import random\n",
    "directories = [\n",
    "    'C:/Users/hp/Downloads/music/Data',\n",
    "    '/content/spectrograms3sec/train',\n",
    "    '/content/spectrograms3sec/test'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'pop', 'hiphop','metal', 'reggae', 'rock']\n",
    "\n",
    "for g in genres:\n",
    "    path_audio = os.path.join('/content/audio3sec', f'{g}')\n",
    "    if not os.path.exists(path_audio):\n",
    "        os.makedirs(path_audio)\n",
    "    path_train = os.path.join('/content/gdrive/My Drive/spectrograms3sec/train', f'{g}')\n",
    "    if not os.path.exists(path_train):\n",
    "        os.makedirs(path_train)\n",
    "    path_test = os.path.join('/content/gdrive/My Drive/spectrograms3sec/test', f'{g}')\n",
    "    if not os.path.exists(path_test):\n",
    "        os.makedirs(path_test)\n",
    "\n",
    "\n",
    "from pydub import AudioSegment\n",
    "i = 0\n",
    "for g in genres:\n",
    "  j=0\n",
    "  print(f\"{g}\")\n",
    "  for filename in os.listdir(os.path.join('C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\genres_original',f\"{g}\")):\n",
    "\n",
    "    song  =  os.path.join(f'C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\genres_original',f\"{g}\",f'{filename}')\n",
    "    j = j+1\n",
    "    for w in range(0,10):\n",
    "      i = i+1\n",
    "      #print(i)\n",
    "      t1 = 3*(w)*1000\n",
    "      t2 = 3*(w+1)*1000\n",
    "      newAudio = AudioSegment.from_wav(song)\n",
    "      new = newAudio[t1:t2]\n",
    "      new.export(f'/content/audio3sec/{g}/{g+str(j)+str(w)}.wav', format=\"wav\")\n",
    "\n",
    "import os\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'pop', 'hiphop','metal', 'reggae', 'rock']\n",
    "for g in genres:\n",
    "  j = 0\n",
    "  print(g)\n",
    "  directory=rf'C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\spectograms3sec//{g}'\n",
    "  os.makedirs(directory,exist_ok=True)\n",
    "  for filename in os.listdir(os.path.join('C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\genres_original',f\"{g}\")):\n",
    "    song  =  os.path.join(f'C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\genres_original\\\\{g}',f'{filename}')\n",
    "    j = j+1\n",
    "    \n",
    "    y,sr = librosa.load(song,duration=3)\n",
    "    #print(sr)\n",
    "    mels = librosa.feature.melspectrogram(y=y,sr=sr)\n",
    "    fig = plt.Figure()\n",
    "    canvas = FigureCanvas(fig)\n",
    "    p = plt.imshow(librosa.power_to_db(mels,ref=np.max))\n",
    "    plt.savefig(f'C:\\\\Users\\\\hp\\\\Downloads\\\\music\\\\Data\\\\spectograms3sec//{g}//{g+str(j)}.png')\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 0.2   \n",
    "random_state = 42  \n",
    "\n",
    "for g in genres:\n",
    "    train_dir = f'C:/Users/hp/Downloads/music/Data/spectograms3sec/train/{g}'\n",
    "    test_dir = f'C:/Users/hp/Downloads/music/Data/spectrograms3sec/test/{g}'\n",
    "    \n",
    "    os.makedirs(test_dir, exist_ok=True)\n",
    "\n",
    "    files = os.listdir(train_dir)\n",
    "\n",
    "    train_files, test_files = train_test_split(files, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    for file in test_files:\n",
    "        src = os.path.join(train_dir, file)\n",
    "        dst = os.path.join(test_dir, file)\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "print(\"Data split complete.\")\n",
    "\n",
    "\n",
    "train_dir = \"C:/Users/hp/Downloads/music/Data/spectograms3sec/train/\"\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,target_size=(288,432),color_mode=\"rgba\",class_mode='categorical',batch_size=128)\n",
    "\n",
    "validation_dir = \"C:/Users/hp/Downloads/music/Data/spectrograms3sec/test/\"\n",
    "vali_datagen = ImageDataGenerator(rescale=1./255)\n",
    "vali_generator = vali_datagen.flow_from_directory(validation_dir,target_size=(288,432),color_mode='rgba',class_mode='categorical',batch_size=128)\n",
    "\n",
    "\n",
    "def GenreModel(input_shape = (288,432,4),classes=9):\n",
    "  \n",
    "  X_input = Input(input_shape)\n",
    "\n",
    "  X = Conv2D(8,kernel_size=(3,3),strides=(1,1))(X_input)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(16,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(32,kernel_size=(3,3),strides = (1,1))(X)\n",
    "  X = BatchNormalization(axis=3)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  X = Conv2D(64,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "  \n",
    "  X = Conv2D(128,kernel_size=(3,3),strides=(1,1))(X)\n",
    "  X = BatchNormalization(axis=-1)(X)\n",
    "  X = Activation('relu')(X)\n",
    "  X = MaxPooling2D((2,2))(X)\n",
    "\n",
    "  \n",
    "  X = Flatten()(X)\n",
    "  \n",
    "  X = Dropout(rate=0.3)\n",
    "\n",
    "  X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "  model = Model(inputs=X_input,outputs=X,name='GenreModel')\n",
    "\n",
    "  return model\n",
    "\n",
    "classes = len(genres)\n",
    "from keras.layers import Dropout\n",
    "import keras.backend as K\n",
    "\n",
    "def get_f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2 * (precision * recall) / (precision + recall + K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "X_input = Input(shape=(288, 432, 4), name='input_layer')\n",
    "X = X_input\n",
    "\n",
    "# Rest of your model architecture\n",
    "\n",
    "X = Flatten()(X)\n",
    "X = Dropout(rate=0.3)(X)  # Apply Dropout layer after Flatten\n",
    "\n",
    "X = Dense(classes, activation='softmax', name='fc' + str(classes))(X)\n",
    "\n",
    "model = Model(inputs=X_input, outputs=X, name='GenreModel')\n",
    "\n",
    "opt = Adam(learning_rate=0.0005)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy', get_f1])\n",
    "\n",
    "model.fit_generator(train_generator, epochs=70, validation_data=vali_generator)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = model.fit_generator(train_generator, epochs=70, validation_data=vali_generator)\n",
    "\n",
    "accuracy = history.history['accuracy']\n",
    "loss = history.history['loss']\n",
    "val_accuracy = history.history['val_accuracy']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot(accuracy, label='Training Accuracy')\n",
    "plt.plot(val_accuracy, label='Validation Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "model.save('C:\\\\Users\\\\hp\\\\Downloads\\\\music')\n",
    "\n",
    "\n",
    "import tensorflow.keras.models as models\n",
    "\n",
    "# Define the custom object\n",
    "class MeanMetricWrapper:\n",
    "    def __init__(self, metric):\n",
    "        self.metric = metric\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.metric(*args, **kwargs)\n",
    "\n",
    "# Define your custom metric function\n",
    "def get_f1(y_true, y_pred):\n",
    "    # Implementation of your custom metric\n",
    "    # ...\n",
    "\n",
    "# Load the model with the custom object\n",
    "       model = models.load_model('C:\\\\Users\\\\hp\\\\Downloads\\\\music',     custom_objects={'MeanMetricWrapper': MeanMetricWrapper(get_f1)    }       )    \n",
    "\n",
    "# Save the model again\n",
    "model.save('C:\\\\Users\\\\hp\\\\Downloads\\\\music_updated')\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Define the custom object\n",
    "class MeanMetricWrapper:\n",
    "    def __init__(self, metric):\n",
    "        self.metric = metric\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        return self.metric(*args, **kwargs)\n",
    "\n",
    "# Define your custom metric function\n",
    "def get_f1(y_true, y_pred):\n",
    "    # Implementation of your custom metric\n",
    "    # ...\n",
    "\n",
    "# Load the trained model with the custom object\n",
    "  model = tf.keras.models.load_model('C:\\\\Users\\\\hp\\\\Downloads\\\\music_updated', custom_objects={'MeanMetricWrapper': MeanMetricWrapper(get_f1)})\n",
    "\n",
    "# Set the path to the test data directory\n",
    "test_data_dir = 'C:/Users/hp/Downloads/music/Data/spectrograms3sec/test/'\n",
    "\n",
    "# Get the list of genres\n",
    "genres = ['blues', 'classical', 'country', 'disco', 'pop', 'hiphop', 'metal', 'reggae', 'rock']\n",
    "\n",
    "# Iterate over the test data for each genre\n",
    "for genre in genres:\n",
    "    genre_dir = os.path.join(test_data_dir, genre)\n",
    "    genre_files = os.listdir(genre_dir)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    # Iterate over each test image in the genre directory\n",
    "    # Iterate over the test data for each genre\n",
    "for genre in genres:\n",
    "    genre_dir = os.path.join(test_data_dir, genre)\n",
    "    genre_files = os.listdir(genre_dir)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for filename in genre_files:\n",
    "        img_path = os.path.join(genre_dir, filename)\n",
    "        img = image.load_img(img_path, target_size=(288, 432))\n",
    "        img_array = image.img_to_array(img)\n",
    "        \n",
    "        # Add an alpha channel to the image\n",
    "        img_array = np.concatenate([img_array, np.zeros((img_array.shape[0], img_array.shape[1], 1))], axis=-1)\n",
    "        \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        preprocessed_img = img_array / 255.0  # Normalize the image\n",
    "\n",
    "        # Make prediction\n",
    "        predictions = model.predict(preprocessed_img)\n",
    "        predicted_class = np.argmax(predictions)\n",
    "        \n",
    "        # Print the predicted class and compare with the ground truth\n",
    "        print('Predicted class:', predicted_class, 'Ground truth:', genres.index(genre))\n",
    "        if predicted_class == genres.index(genre):\n",
    "            correct_predictions += 1\n",
    "        total_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    print('Genre:', genre, 'Accuracy:', accuracy)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import librosa\n",
    "from scipy import signal\n",
    "\n",
    "# Load the audio file\n",
    "audio_path = 'C:\\\\Users\\\\hp\\\\Downloads\\\\nsqiv-0otrm.wav'\n",
    "audio, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "# Preprocess the audio data to generate a spectrogram\n",
    "# You can adjust the parameters according to your requirements\n",
    "window_size = 1024\n",
    "hop_length = 512\n",
    "n_fft = 1024\n",
    "\n",
    "_, _, spectrogram = signal.spectrogram(audio, fs=sr, window='hann', nperseg=window_size, noverlap=window_size-hop_length, nfft=n_fft)\n",
    "\n",
    "# Normalize the spectrogram\n",
    "spectrogram = np.log1p(spectrogram)\n",
    "\n",
    "# Resize the spectrogram to match the input shape of the model\n",
    "input_shape = (spectrogram.shape[0], spectrogram.shape[1], 1)\n",
    "spectrogram = tf.image.resize(spectrogram, input_shape[:-1])\n",
    "\n",
    "# Expand dimensions to match the batch size expected by the model\n",
    "spectrogram = np.expand_dims(spectrogram, axis=0)\n",
    "\n",
    "# Load the model\n",
    "model_path = 'C:\\\\Users\\\\hp\\\\Downloads\\\\music_updated'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(spectrogram)\n",
    "\n",
    "# Get the predicted class label\n",
    "predicted_class = np.argmax(predictions, axis=-1)\n",
    "\n",
    "# Print the predicted class label\n",
    "print('Predicted class:', predicted_class)\n",
    "\n",
    "\n",
    "import glob\n",
    "\n",
    "# Search for the model file by name\n",
    "model_files = glob.glob('**/music_updated.h5', recursive=True)\n",
    "\n",
    "# Print the paths of all the matching files\n",
    "for file in model_files:\n",
    "    print(\"Model file found:\", file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
